
NAME: ''
#OUTPUT_DIR: './output/ERA-RDFCL/cifar10/ResNet32/Base0/task2/seed-0/No-FCN/test1'
OUTPUT_DIR: './output/EARS_DFCL/visualize/cifar10/ResNet32/Base0/task2/FCTM-ABD/model-LwF-RTKD-ABD/seed-0/test1'
SHOW_STEP: 50
SAVE_STEP: 100
VALID_STEP: 25
INPUT_SIZE: (32, 32)
COLOR_SPACE: 'RGB'
CPU_MODE: False
use_best_model: False
#task1_MODEL: "/data0/user/kcli/CL_research/QuintCDKD/reuse-model/cifar100-base0-task5-base_latest_model.pth"
#task1_MODEL: "/data0/user/kcli/CL_research/QuintCDKD/reuse-model/cifar100-base0-task10-base_latest_model.pth"
#task1_MODEL: "/data0/user/kcli/CL_research/QuintCDKD/reuse-model/cifar100-base0-task20-base_latest_model.pth"
#task1_MODEL: "/home/likunchi/CL_research/DataFreeCL-V2/output/ERA-RDFCL/cifar10/ResNet32/Base0/task5/seed-10/test2/models/base_latest_model.pth"
#task1_MODEL: "/data0/user/kcli/CL_research/QuintCDKD/reuse-model/cifar10-base0-task2-base_latest_model.pth"
task1_MODEL: "/home/likunchi/CL_research/DataFreeCL/output/ERA-RDFCL/cifar10/ResNet32/Base0/task2/seed-0/test1/models/base_latest_model.pth"
pretrained_MODEL: ""
use_base_half: False
checkpoints: ''
save_model: True
use_Contra_train_transform: False
train_first_task: False

seed: 0
trainer_name: "EARS_DFCL"
# ----- DATASET BUILDER -----

DATASET:
  dataset: "Torchvision_Datasets_Split"
  dataset_name: "CIFAR10"                  #mnist, mnist28, CIFAR10, CIFAR100, imagenet, svhn
#  data_root: "/data0/user/kcli/Datasets"
  data_root: "/home/likunchi/Datasets"
  all_classes: 10
  all_tasks: 2
  split_seed: 0
  val_length: 0
# ----- resume -----

RESUME:
  use_resume: False
  resumed_model_path: ""

# ----- pre-train setting -----
PRETRAINED:
  use_pretrained_model: False
  MODEL: ""


# ----- extractor BUILDER -----
extractor:
#  TYPE: 'resnet18'
  #TYPE: "resnet34"
  TYPE: "res32_cifar"
  rate: 1.
  output_feature_dim: 64

generator:
  gen_model_name: "CIFAR_GEN"
  generator_iter: 10000
  batch_size: 128
  deep_inv_params: [1.e-3, 50, 1.0e-3, 1000] # generator_lr, r_feature_weight, pr_scale, content_temp 1e-3 5e1 1e-3 1e3

#----- model -----
model:
#cls loss:
  softTarget_lambda: 1.
#  cls_type: "softTarget"
#  cls_type: "adjusted_logit"
#  cls_type: "FTCE"
  cls_type: "LwF"
#  cls_type: "iCaRL"

#logit KD:
  T: 2.
#  KD_type: "ReKD"
  KD_type: "RTKD"
#  KD_type: "BKD"
#  KD_type: "TKD"
#  KD_type: "null"
  kd_lambda: 1.

# feature KD
  fkd_lambda: 0.1
  use_featureKD: False
  use_ABD_loss: False
  use_cls_loss: True
  ce_lambda: 0.5
  hkd_lambda: 0.15
  rkd_lambda: 0.5

  TRAIN:
    BATCH_SIZE: 128
#    MAX_EPOCH: 250
    MAX_EPOCH: 170
    NUM_WORKERS: 4
    SHUFFLE: True
    OPTIMIZER:
      TYPE: 'SGD'
      BASE_LR: 0.1
      MOMENTUM: 0.9
      WEIGHT_DECAY: 2e-4
    LR_SCHEDULER:
      TYPE: 'warmup'
#      LR_STEP: [100, 150, 200, 250]
      LR_STEP: [60, 100, 130, 150]
      LR_FACTOR: 0.1
      WARM_EPOCH: 5

  finetune:
    MAX_EPOCH: 60
    BATCH_SIZE: 128
    SHUFFLE: True
    NUM_WORKERS: 4
    # ----- OPTIMIZER -----
    BASE_LR: 0.005
    TYPE: "SGD"
    MOMENTUM: 0.9
    WEIGHT_DECAY: 2e-4
    # ----- LR_SCHEDULER -----
    LR_TYPE: "multistep"
    LR_STEP: [ 30, 50 ]
    LR_FACTOR: 0.1
    WARM_EPOCH: 5

#----- FCTM -----
FCTM:

# classification loss:
  use_ABD_KD: False

  ce_lambda: 0.5
  addCls_lambda: 1.
  allcls_lambda: 1.
  all_cls_LOSS_TYPE: "CE"
  add_cls_LOSS_TYPE: "CE"

# logit KD:
  T: 2.
  hkd_lambda: 0.15
  kd_lambda: 1.

# rkd:
  rkd_lambda: 0.5


  use_FCN: False
  FCN:
    in_feature_dim: 128
    out_feature_dim: 64
    layer_nums: 3
    hidden_layer_rate: 2
    last_hidden_layer_use_relu: True
  TRAIN:
    tradeoff_rate: 1.
    BATCH_SIZE: 128
    MAX_EPOCH: 170
    #MAX_EPOCH: 160
    NUM_WORKERS: 1
    SHUFFLE: True
    OPTIMIZER:
      TYPE: 'SGD'
      BASE_LR: 0.1
      MOMENTUM: 0.9
      WEIGHT_DECAY: 2e-4
    LR_SCHEDULER:
      #TYPE: "CosineAnnealing"
      TYPE: 'warmup'
#      LR_STEP: [100, 150, 200, 250]
      LR_STEP: [60, 100, 130, 150]
      LR_FACTOR: 0.1
      WARM_EPOCH: 5



